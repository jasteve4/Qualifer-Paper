
@techreport{Asanović:EECS-2016-17,
    Author = {Asanović, Krste and Avizienis, Rimas and Bachrach, Jonathan and Beamer, Scott and Biancolin, David and Celio, Christopher and Cook, Henry and Dabbelt, Daniel and Hauser, John and Izraelevitz, Adam and Karandikar, Sagar and Keller, Ben and Kim, Donggyu and Koenig, John and Lee, Yunsup and Love, Eric and Maas, Martin and Magyar, Albert and Mao, Howard and Moreto, Miquel and Ou, Albert and Patterson, David A. and Richards, Brian and Schmidt, Colin and Twigg, Stephen and Vo, Huy and Waterman, Andrew},
    Title = {The Rocket Chip Generator},
    Institution = {EECS Department, University of California, Berkeley},
    Year = {2016},
    Month = {Apr},
    URL = {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-17.html},
    Number = {UCB/EECS-2016-17},
    Abstract = {Rocket Chip is an open-source Sysem-on-Chip design generator that emits synthesizable RTL. It leverages the Chisel hardware construction language to compose a library of sophisticated generators for cores, caches, and interconnects into an integrated SoC. Rocket Chip generates general-purpose processor cores that use the open RISC-V ISA, and provides both an in-order core generator (Rocket) and an out-of-order core generator (BOOM). For SoC designers interested in utilizing heterogeneous specialization for added efficiency gains, Rocket Chip supports the integration of custom accelerators in the form of instruction set extensions, coprocessors, or fully independent novel cores. Rocket Chip has been taped out (manufactured) eleven times, and yielded functional silicon prototypes capable of booting Linux.}
}
@INPROCEEDINGS{8697413,
author={S. {Dey} and P. D. {Franzon}},
booktitle={20th International Symposium on Quality Electronic Design (ISQED)},
title={An Application Specific Processor Architecture with 3D Integration for Recurrent Neural Networks},
year={2019},
volume={},
number={},
pages={183-190},
keywords={instruction sets;learning (artificial intelligence);multiprocessing systems;recurrent neural nets;recurrent neural network;application-specific instruction set processor;application specific processor architecture;deep learning;multimodal natural data;artificial intelligence;3D hardware architecture;3D-stacked memory;sized on-chip memory;high-level programming environment;Very Long Instruction Word instructions;Training;Hardware;Computer architecture;Three-dimensional displays;Bandwidth;Random access memory;Registers;deep learning;accelerator;LSTM;ASIP},
doi={10.1109/ISQED.2019.8697413},
ISSN={},
month={March},}
@INPROCEEDINGS{7905453,
author={W. {Li} and P. {Franzon}},
booktitle={2016 29th IEEE International System-on-Chip Conference (SOCC)},
title={Hardware implementation of Hierarchical Temporal Memory algorithm},
year={2016},
volume={},
number={},
pages={133-138},
keywords={application specific integrated circuits;integrated memory circuits;matrix algebra;microprocessor chips;neural chips;hierarchical temporal memory algorithm;hardware implementation;ASIC;Numenta HTM algorithm;neural network;processing element;neuron cells;dedicated register files;identical cell modules;centralized memory organization;PE matrix;mesh network;high order network;first order network;MNIST dataset;inference mode;CPU;learning mode;power 1.29 mW;time 4.52 mus;time 4.39 mus;Neurons;Biological neural networks;Pattern recognition;Hardware;Memory management;Mesh networks;Machine learning algorithms;HTM Network;ASIC Design;Distributed Memory;MNIST Dataset},
doi={10.1109/SOCC.2016.7905453},
ISSN={},
month={Sep.},}
@phdthesis{DeySumon,
    title    = {An examination of keystroke dynamics for continuous user authentication},
    school   = {North Carolina State University},
    author   = {Dey, Sumon},
    year     = {2019},
    type     = {{PhD} dissertation},
}
@phdthesis{LeWeifuDissertation,
    title    = {Design of Hardware Accelerators for Hierarchical Temporal Memory and Convolutional Neural Network.},
    school   = {North Carolina State University},
    author   = {Li, Weifu},
    year     = {2019},
    type     = {{PhD} dissertation},
}
